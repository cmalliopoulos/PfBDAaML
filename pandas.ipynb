{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLTrain logo](https://mltrain.cc/wp-content/uploads/2017/11/mltrain_logo-4.png \"MLTrain logo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    @import url('https://fonts.googleapis.com/css?family=Roboto+Condensed');\n",
       "    </style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> .container {width: 90%} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> .CodeMirror {font-size: 10.5pt !important} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> div.cell.selected{border: 0px};</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       "    .text_cell_render {\n",
       "        font-family: \"Roboto Condensed\"; \n",
       "        line-height: 145%; \n",
       "        font-size: 13pt} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       "    .output_area {font-size: large} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!wget -q -O changeNBLayout.py https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/changeNBLayout.py\n",
    "%run changeNBLayout.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "The pandas library implements the basic machinery for handling in-memory tabular data with Python.  \n",
    "It is a large library. Contains >600 methods, attributes and functions.  \n",
    "The online documentation of the current version (0.21) is available at https://pandas.pydata.org/pandas-docs/stable/overview.html.  \n",
    "  \n",
    "The core data structures in Pandas are the __Series, DataFrame and Index objects__.  \n",
    "You should think of Series and DataFrames as fact tables (ie with named and typed columns) and Indices as Dimensions with hierarchies.  \n",
    "  \n",
    "Pandas' methods and funtions permit standard __dimensional analysis__ (slicing, dicing and pivoting). Moreover Pandas provides a comprehensive set of analytical functions for __group transforms and ranking__.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBS player stats: \n",
      "                  Name                   Team  Number Position  Age Height  Weight    College   Salary\n",
      "314        Kyle Korver          Atlanta Hawks      26       SG   35    6-7     212  Creighton  5746479\n",
      "24    Chris McCullough          Brooklyn Nets       1       PF   21   6-11     200   Syracuse  1140240\n",
      "255         Josh Smith        Houston Rockets       5        C   30    6-9     225        NaN   947276\n",
      "204        Ian Mahinmi         Indiana Pacers      28        C   29   6-11     250        NaN  4000000\n",
      "88   Marreese Speights  Golden State Warriors       5        C   28   6-10     255    Florida  3815000\n",
      " \n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management          Team\n",
      "326    Jeffrey    Male 1997-06-18 2017-11-24 20:01:00   45150   12.075              True       Product\n",
      "283       Todd    Male 2009-03-11 2017-11-24 03:43:00  107281    1.612              True   Engineering\n",
      "430     Andrea  Female 2010-10-01 2017-11-24 11:54:00   79123   19.422             False  Distribution\n",
      "581     Ernest    Male 1990-01-28 2017-11-24 00:08:00   81919   15.118             False     Marketing\n",
      "154    Rebecca  Female 1980-11-15 2017-11-24 04:13:00   85730    5.359              True       Product\n"
     ]
    }
   ],
   "source": [
    "from os import linesep as endl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Adjust Pandas layout options\n",
    "pd.set_option('display.width', 124)\n",
    "\n",
    "! wget -q -O nba.csv https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/nba.csv\n",
    "nba = pd.read_csv('nba.csv')\n",
    "print 'NBS player stats:', endl, nba.sample(5)\n",
    "\n",
    "! wget -q -O employees.csv https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/employees.csv\n",
    "emp = pd.read_csv(\"employees.csv\", parse_dates = [\"Start Date\", \"Last Login Time\"])\n",
    "print '', endl, emp.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introspection methods and attributes #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes have quite a few object attributes for __introspection__ and convenience methods for querying their __content__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print first 5 rows \n",
      "            Name            Team  Number Position  Age Height  Weight            College   Salary\n",
      "0  Avery Bradley  Boston Celtics       0       PG   25    6-2     180              Texas  7730337\n",
      "1    Jae Crowder  Boston Celtics      99       SF   25    6-6     235          Marquette  6796117\n",
      "2   John Holland  Boston Celtics      30       SG   27    6-5     205  Boston University      NaN\n",
      "3    R.J. Hunter  Boston Celtics      28       SG   22    6-5     185      Georgia State  1148640\n",
      "4  Jonas Jerebko  Boston Celtics       8       PF   29   6-10     231                NaN  5000000\n",
      "\n",
      "Print 5 last rows \n",
      "             Name       Team  Number Position  Age Height  Weight College   Salary\n",
      "453  Shelvin Mack  Utah Jazz       8       PG   26    6-3     203  Butler  2433333\n",
      "454     Raul Neto  Utah Jazz      25       PG   24    6-1     179     NaN   900000\n",
      "455  Tibor Pleiss  Utah Jazz      21        C   26    7-3     256     NaN  2900000\n",
      "456   Jeff Withey  Utah Jazz      24        C   26    7-0     231  Kansas   947276\n",
      "457           NaN        NaN     NaN      NaN  NaN    NaN     NaN     NaN      NaN\n",
      "\n",
      "A random sample of 5 rows \n",
      "                 Name                  Team  Number Position  Age Height  Weight    College    Salary\n",
      "157        Taj Gibson         Chicago Bulls      22       PF   30    6-9     225        USC   8500000\n",
      "275     Alexis Ajinca  New Orleans Pelicans      42        C   28    7-2     248        NaN   4389607\n",
      "143  DeMarcus Cousins      Sacramento Kings      15        C   25   6-11     270   Kentucky  15851950\n",
      "189     Tobias Harris       Detroit Pistons      34       SF   23    6-9     235  Tennessee  16000000\n",
      "168      Kyrie Irving   Cleveland Cavaliers       2       PG   24    6-3     193       Duke  16407501\n",
      "\n",
      "Column types \n",
      "Name         object\n",
      "Team         object\n",
      "Number      float64\n",
      "Position     object\n",
      "Age         float64\n",
      "Height       object\n",
      "Weight      float64\n",
      "College      object\n",
      "Salary      float64\n",
      "dtype: object\n",
      "\n",
      "column names \n",
      "Index([u'Name', u'Team', u'Number', u'Position', u'Age', u'Height', u'Weight', u'College', u'Salary'], dtype='object')\n",
      "\n",
      "The index object \n",
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "            ...\n",
      "            448, 449, 450, 451, 452, 453, 454, 455, 456, 457],\n",
      "           dtype='int64', length=458)\n",
      "\n",
      "DataFrame values as array \n",
      "[['Avery Bradley' 'Boston Celtics' 0.0 ..., 180.0 'Texas' 7730337.0]\n",
      " ['Jae Crowder' 'Boston Celtics' 99.0 ..., 235.0 'Marquette' 6796117.0]\n",
      " ['John Holland' 'Boston Celtics' 30.0 ..., 205.0 'Boston University' nan]\n",
      " ..., \n",
      " ['Tibor Pleiss' 'Utah Jazz' 21.0 ..., 256.0 nan 2900000.0]\n",
      " ['Jeff Withey' 'Utah Jazz' 24.0 ..., 231.0 'Kansas' 947276.0]\n",
      " [nan nan nan ..., nan nan nan]]\n",
      "\n",
      "Shape \n",
      "(458, 9)\n",
      "\n",
      "Number of elements \n",
      "4122\n",
      "\n",
      "Basic statistics \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 458 entries, 0 to 457\n",
      "Data columns (total 9 columns):\n",
      "Name        457 non-null object\n",
      "Team        457 non-null object\n",
      "Number      457 non-null float64\n",
      "Position    457 non-null object\n",
      "Age         457 non-null float64\n",
      "Height      457 non-null object\n",
      "Weight      457 non-null float64\n",
      "College     373 non-null object\n",
      "Salary      446 non-null float64\n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 35.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print 'Print first 5 rows', endl, nba.head(5)\n",
    "print endl, 'Print 5 last rows', endl, nba.tail()\n",
    "print endl, 'A random sample of 5 rows', endl, nba.sample(5)\n",
    "print endl, 'Column types', endl, nba.dtypes\n",
    "print endl, 'column names', endl, nba.columns\n",
    "print endl, 'The index object', endl, nba.index\n",
    "print endl, 'DataFrame values as array', endl, nba.values\n",
    "print endl, 'Shape', endl, nba.shape\n",
    "print endl, 'Number of elements', endl, nba.size\n",
    "print endl, 'Basic statistics', endl, nba.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Column types__ can be set programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before type-setting: \n",
      "First Name                   object\n",
      "Gender                       object\n",
      "Start Date           datetime64[ns]\n",
      "Last Login Time      datetime64[ns]\n",
      "Salary                        int64\n",
      "Bonus %                     float64\n",
      "Senior Management            object\n",
      "Team                         object\n",
      "dtype: object\n",
      "\n",
      "After type-setting \n",
      "First Name                   object\n",
      "Gender                     category\n",
      "Start Date           datetime64[ns]\n",
      "Last Login Time      datetime64[ns]\n",
      "Salary                        int64\n",
      "Bonus %                     float64\n",
      "Senior Management              bool\n",
      "Team                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print 'Before type-setting:', endl, emp.dtypes\n",
    "\n",
    "# Change types programmatically\n",
    "emp[\"Senior Management\"] = emp[\"Senior Management\"].astype('bool')\n",
    "emp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n",
    "\n",
    "print endl, 'After type-setting', endl, emp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary ctor:\n",
      "   pop   state  year\n",
      "0  1.5    Ohio  2000\n",
      "1  1.7    Ohio  2001\n",
      "2  3.6    Ohio  2002\n",
      "3  2.4  Nevada  2001\n",
      "4  2.9  Nevada  2002\n",
      "\n",
      "If you specify a different order in \"columns\" the df will be arranged properly:\n",
      "   year   state  pop\n",
      "0  2000    Ohio  1.5\n",
      "1  2001    Ohio  1.7\n",
      "2  2002    Ohio  3.6\n",
      "3  2001  Nevada  2.4\n",
      "4  2002  Nevada  2.9\n",
      "\n",
      "Non-existing columns fill the DataFrame with nulls:\n",
      "       year   state  pop debt\n",
      "one    2000    Ohio  1.5  NaN\n",
      "two    2001    Ohio  1.7  NaN\n",
      "three  2002    Ohio  3.6  NaN\n",
      "four   2001  Nevada  2.4  NaN\n",
      "five   2002  Nevada  2.9  NaN\n",
      "\n",
      "A nested dict creates column and index objects:\n",
      "      Nevada  Ohio\n",
      "2000     NaN   1.5\n",
      "2001     2.4   1.7\n",
      "2002     2.9   3.6\n",
      "\n",
      "Index and columns can be named:\n",
      "colNames    year state   pop\n",
      "ixNames                     \n",
      "one         Ohio   1.5  2000\n",
      "two         Ohio   1.7  2001\n",
      "three       Ohio   3.6  2002\n",
      "four      Nevada   2.4  2001\n",
      "five      Nevada   2.9  2002\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "    'year': [2000, 2001, 2002, 2001, 2002],\n",
    "    'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "\n",
    "print 'Dictionary ctor:'\n",
    "print pd.DataFrame(data)\n",
    "\n",
    "print endl, 'If you specify a different order in \"columns\" the df will be arranged properly:'\n",
    "print pd.DataFrame(data, columns = ['year', 'state', 'pop'])\n",
    "\n",
    "frame2 = pd.DataFrame(\n",
    "    data, \n",
    "    columns = ['year', 'state', 'pop', 'debt'],\n",
    "    index = ['one', 'two', 'three', 'four', 'five'])\n",
    "print endl, 'Non-existing columns fill the DataFrame with nulls:'\n",
    "print frame2\n",
    "\n",
    "pop = {'Nevada': {2001: 2.4, 2002: 2.9}, 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}\n",
    "frame3 = pd.DataFrame(pop)\n",
    "\n",
    "print endl, 'A nested dict creates column and index objects:'\n",
    "print frame3\n",
    "\n",
    "listT = lambda _: np.array(_).T\n",
    "frame4 = pd.DataFrame(\n",
    "    data = listT(data.values()), \n",
    "    index = ['one', 'two', 'three', 'four', 'five'], \n",
    "    columns = ['year', 'state', 'pop'])\n",
    "\n",
    "frame4.index.name = 'ixNames'\n",
    "frame4.columns.name = 'colNames'\n",
    "\n",
    "print endl, 'Index and columns can be named:'\n",
    "print frame4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "# Projection and selection #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio             2\n",
      "Colorado         5\n",
      "Utah             6\n",
      "New York         0\n",
      "Atlanta          9\n",
      "San Francisco    8\n",
      "Name: one, dtype: int64\n",
      "               one  two\n",
      "Ohio             2    3\n",
      "Colorado         5    5\n",
      "Utah             6    6\n",
      "New York         0    7\n",
      "Atlanta          9    8\n",
      "San Francisco    8    4\n",
      "               one  two  four\n",
      "Ohio             2    3     4\n",
      "Colorado         5    5     0\n",
      "Utah             6    6     2\n",
      "New York         0    7     4\n",
      "Atlanta          9    8     0\n",
      "San Francisco    8    4     1\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "    np.random.choice(10, 24).reshape((6, 4)),\n",
    "    index = ['Ohio', 'Colorado', 'Utah', 'New York', 'Atlanta', 'San Francisco'],\n",
    "    columns = ['one', 'two', 'three', 'four'])\n",
    "\n",
    "# Projections\n",
    "print data['one']\n",
    "print data[['one', 'two']]\n",
    "print data[[col for col in data.columns if 'o' in col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by index ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two      8\n",
       "three    5\n",
       "Name: Atlanta, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selection by index label\n",
    "data.loc['Ohio']\n",
    "data.loc['Ohio':'Utah']\n",
    "data.loc[['Ohio', 'New York']]\n",
    "\n",
    "# Integer selection\n",
    "data.iloc[2:4]\n",
    "data.iloc[::-1]\n",
    "data[2:4]\n",
    "\n",
    "\n",
    "# Simultaneous selection by label and projection\n",
    "data.loc['Atlanta', ['two', 'three']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean and relational selections ###\n",
    "\n",
    "We can specify __index__ shards (position lists and ranges) by boolean or relational expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management       Team\n",
      "26       Craig    Male 2000-02-27 2017-11-24 07:45:00   37598    7.757              True  Marketing\n",
      "883    Kathryn  Female 1995-10-27 2017-11-24 15:39:00   57300   18.015             False  Marketing\n",
      "\n",
      "    First Name Gender Start Date     Last Login Time  Salary  Bonus % Senior Management   Team\n",
      "873      Jason   Male 1998-05-01 2017-11-24 18:05:00   75607    4.299              True  Sales\n",
      "592     Justin   Male 1981-05-24 2017-11-24 23:15:00   78351   15.221             False  Sales\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management       Team\n",
      "220        NaN  Female 1991-06-17 2017-11-24 12:49:00   71945    5.560              True  Marketing\n",
      "516     Gloria  Female 1992-04-12 2017-11-24 20:26:00   66224   15.979              True      Legal\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management          Team\n",
      "40     Michael    Male 2008-10-10 2017-11-24 11:25:00   99283    2.665              True  Distribution\n",
      "235      Norma  Female 2015-02-11 2017-11-24 23:44:00   94393    3.643              True   Engineering\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management          Team\n",
      "600    Barbara     NaN 1994-12-20 2017-11-24 10:09:00   90556   15.749              True  Distribution\n",
      "261      Marie  Female 1995-08-06 2017-11-24 13:58:00  100308   13.677             False       Product\n",
      "758       Carl     NaN 2007-08-18 2017-11-24 08:01:00   98295    7.617              True         Legal\n",
      "541       Ruby  Female 1999-05-01 2017-11-24 03:36:00  147362    7.851              True   Engineering\n",
      "348     Philip    Male 1989-08-02 2017-11-24 11:21:00  129968   19.897             False       Finance\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management             Team\n",
      "214      Julie  Female 1989-07-23 2017-11-24 13:52:00  109588    3.550             False      Engineering\n",
      "870    Cynthia     NaN 1996-11-19 2017-11-24 22:40:00  107816   18.751             False        Marketing\n",
      "815      Maria     NaN 1986-01-18 2017-11-24 20:36:00  106562    4.000             False  Human Resources\n",
      "255     Denise  Female 2009-03-20 2017-11-24 07:57:00  115118    5.108             False  Human Resources\n"
     ]
    }
   ],
   "source": [
    "# Selection based on categories\n",
    "print emp[emp['Team'] == 'Marketing'].sample(2)\n",
    "print endl, emp[(emp['Gender'] == 'Male') & (emp['Team'] == 'Sales')].sample(2)\n",
    "print endl, emp[(emp['Gender'] == 'Female') & ~(emp['First Name'] == 'Mary')].sample(2)\n",
    "\n",
    "# Selection based on scalars\n",
    "print endl, emp[emp['Start Date'] > '1990-01-01'].sample(2)\n",
    "\n",
    "# a more complex condition\n",
    "print endl, emp[~emp['Team'].isin(['Marketing', 'Sales'])].sample(5, replace = False)\n",
    "\n",
    "print endl, emp[emp['Salary'].between(80000, 150000)].sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More general selections ###\n",
    "With Dataframes of integral types more general selections are possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of floats: \n",
      "          0         1         2         3         4\n",
      "0 -1.351567 -0.206079  1.469018  0.238091  0.976213\n",
      "1  0.599672  1.613372  0.022147  0.166617 -1.104442\n",
      "2 -0.428363  2.106975  0.389974  0.008080 -1.279482\n",
      "3  0.488893 -0.066330 -0.893561 -0.695361  0.577821\n",
      "4  0.585217 -1.136154  1.285640 -0.157583  0.889713\n",
      "\n",
      "Boolean mask \n",
      "       0      1      2      3      4\n",
      "0  False  False   True  False   True\n",
      "1   True   True  False  False  False\n",
      "2  False   True  False  False  False\n",
      "3  False  False  False  False   True\n",
      "4   True  False   True  False   True\n",
      "\n",
      "Applying mask to df: \n",
      "          0         1         2   3         4\n",
      "0       NaN       NaN  1.469018 NaN  0.976213\n",
      "1  0.599672  1.613372       NaN NaN       NaN\n",
      "2       NaN  2.106975       NaN NaN       NaN\n",
      "3       NaN       NaN       NaN NaN  0.577821\n",
      "4  0.585217       NaN  1.285640 NaN  0.889713\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 5))\n",
    "print 'Dataframe of floats:', endl, df\n",
    "\n",
    "mask = (df > .5)\n",
    "print endl, 'Boolean mask', endl, mask\n",
    "\n",
    "print endl, 'Applying mask to df:', endl, df[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .isnull and .notnull ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574    False\n",
      "561    False\n",
      "371    False\n",
      "825    False\n",
      "731    False\n",
      "Name: Team, dtype: bool\n",
      "\n",
      "First names of employees without team:\n",
      "382        NaN\n",
      "479    Richard\n",
      "851      Bobby\n",
      "520      Peter\n",
      "91       James\n",
      "Name: First Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print emp['Team'].isnull().sample(5)\n",
    "\n",
    "print endl, 'First names of employees without team:'\n",
    "print emp['First Name'][emp['Team'].isnull()].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .unique and .nunique #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas' 'Louise' nan 'James' 'Christopher' 'Jonathan' 'Michael' 'Jeremy'\n",
      " 'Bobby' 'Edward' 'Joyce' 'Jason' 'Chris' 'Richard' 'Wanda' 'Jimmy' 'Peter'\n",
      " 'Kimberly' 'Harry' 'Carl' 'Randy' 'Donald' 'Joseph' 'Alice' 'Todd'\n",
      " 'Daniel' 'Antonio' 'Lawrence' 'Nicole' 'Charles' 'Mildred' 'Phillip'\n",
      " 'Ryan' 'Joe']\n",
      "\n",
      "34\n",
      "\n",
      "Not equal. Why? \n",
      "33\n",
      "\n",
      "Now they're equal: \n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print emp['First Name'][emp['Team'].isnull()].unique()\n",
    "\n",
    "print endl, len(emp['First Name'][emp['Team'].isnull()].unique())\n",
    "\n",
    "print endl, 'Not equal. Why?', endl, emp['First Name'][emp['Team'].isnull()].nunique()\n",
    "\n",
    "print endl, \"Now they're equal:\", endl, emp['First Name'][emp['Team'].isnull()].nunique(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sorting and ranking #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Name Gender Start Date     Last Login Time  Salary  Bonus % Senior Management             Team\n",
      "101      Aaron   Male 2012-02-17 2017-11-24 10:20:00   61602   11.849              True        Marketing\n",
      "327      Aaron   Male 1994-01-29 2017-11-24 18:48:00   58755    5.097              True        Marketing\n",
      "440      Aaron   Male 1990-07-22 2017-11-24 14:53:00   52119   11.343              True  Client Services\n",
      "937      Aaron    NaN 1986-01-22 2017-11-24 19:39:00   63126   18.424             False  Client Services\n",
      "137       Adam   Male 2011-05-21 2017-11-24 01:45:00   95327   15.120             False     Distribution\n",
      "\n",
      "Sort by \"Start Date\" using index sorting\n",
      "\n",
      "           First Name  Gender     Last Login Time  Salary  Bonus % Senior Management             Team\n",
      "Start Date                                                                                           \n",
      "2016-07-15      Terry     NaN 2017-11-24 00:29:00  140002   19.490              True        Marketing\n",
      "2016-06-16       Tina  Female 2017-11-24 19:47:00  100705   16.961              True        Marketing\n",
      "2016-06-05    Lillian  Female 2017-11-24 06:09:00   59414    1.256             False          Product\n",
      "2016-05-24        NaN    Male 2017-11-24 21:17:00   76409    7.008               NaN     Distribution\n",
      "2016-05-12    Lillian     NaN 2017-11-24 15:43:00   64164   17.612             False  Human Resources\n"
     ]
    }
   ],
   "source": [
    "# To sort by the values of one or more columns use sort_values method\n",
    "print emp.sort_values(by = 'First Name', na_position = 'last').head(5)\n",
    "\n",
    "# Create an index by which to sort\n",
    "print endl, 'Sort by \"Start Date\" using index sorting'\n",
    "_0 = emp.set_index(keys = 'Start Date', drop = True)\n",
    "print endl, _0.sort_index(ascending = False, na_position = 'last').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rank` will assign integers to values according to their ordered position.  \n",
    "The ranks can be contiguous or not according to the ranking method. Groups of equal values are always assigned the same rank.  \n",
    "`average` assigns to each equi-valued group the average of their sort-index.  \n",
    "  \n",
    "__NB:__ The ranks of the resulting set are not sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  0  3\n",
      "1  1  1\n",
      "2  4  0\n",
      "3  1  0\n",
      "4  2  0\n",
      "5  4  0\n",
      "6  1  1\n",
      "7  4  4\n",
      "8  2  3\n",
      "9  1  3\n",
      "\n",
      "Default ranks of first column elements 0    1\n",
      "1    5\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Dense ranking \n",
      "          0  0\n",
      "0 -1.351567  1\n",
      "1  0.599672  5\n",
      "2 -0.428363  2\n",
      "3  0.488893  3\n",
      "4  0.585217  4\n"
     ]
    }
   ],
   "source": [
    "# create a dummy DataFrame\n",
    "_1 = pd.DataFrame(np.random.choice(5, [10, 2]))\n",
    "print _1\n",
    "\n",
    "# Default ranking\n",
    "print endl, 'Default ranks of first column elements', df[0].rank()\n",
    "\n",
    "print endl, 'Dense ranking', endl, pd.concat([df[0], df[0].rank(method = 'dense')], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "# Groupings and transforms #\n",
    "\n",
    "Projections and selections when combined with `.groupby`, `.apply` and `.transform` methods described in the sequel, essentially constitute Panda's powerful framework for multidimensional analysis (MDA).  \n",
    "MDA supported by visualizations (an area we'll explore later) is what has been known as __Exploratory Data Analysis__, a term coined in the 70s by John Tukey, one of the prominent statisticians of our era\n",
    "\n",
    "__Quiz:__ What else is [Tukey known for](https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm)? (it dominated the electronics industry for 3 decades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset ###\n",
    "Create a Dataframe with Sales records of an imaginary retailer.  \n",
    "The retailer sells products identified by their Stock-keeping unit (SKU column) in several stores identified by their ID (STORE column).  \n",
    "Each record contains the number and the price of items (SKUs) sold in a store at a particular day.\n",
    "  \n",
    "For our case assume there're 4 SKUs, 5 stores and we have records from 01May2016 to 31Oct2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SKUs\n",
    "storeSales = pd.DataFrame(np.random.choice(list('ABCD'), 100), columns = ['SKU'])\n",
    "# Stores\n",
    "storeSales['STORE'] = np.random.choice(list('WXYZ'), 100)\n",
    "# Dates\n",
    "storeSales['DAY'] = np.random.choice(pd.date_range(start = dt(2016, 5, 1), end = dt(2017, 10, 31)), 100)\n",
    "#Price: \n",
    "prices = dict(zip(list('ABCD'), np.random.uniform(10, 100, 4)))\n",
    "storeSales['PRICE'] = storeSales['SKU'].map(prices)\n",
    "\n",
    "# Items sold. # Permit 0 sales on item\n",
    "storeSales['SALES'] = np.random.uniform(0, 100, 100).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permit some null prices (e.g. assume some SKUs were sold with coupons of varying markdowns)  \n",
    "__Caveat:__  \n",
    "If you try to use instead\n",
    "``` Python\n",
    "storeSales[np.random.choice([True, False], storeSales.shape[0], p = [.05, .95])]['PRICE'] = np.nan\n",
    "```\n",
    "you get a warning that 'you're trying to a ssign to an implicit copy'.  \n",
    "  \n",
    "__Quiz:__ Where's the implicit copy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SKU STORE        DAY      PRICE  SALES\n",
      "20   B     Z 2016-08-05  28.058070     79\n",
      "39   C     Y 2016-07-11  66.801608     17\n",
      "35   A     W 2017-05-13  50.774371     90\n",
      "75   B     X 2016-09-23        NaN     13\n",
      "42   D     W 2016-11-09  11.601213     23\n",
      "16   A     Z 2016-09-22  50.774371     14\n",
      "95   D     W 2016-05-26  11.601213     37\n",
      "61   C     Y 2017-07-16  66.801608     82\n",
      "82   A     Z 2017-07-28  50.774371     34\n",
      "60   D     X 2017-10-29  11.601213     30\n",
      "5    D     X 2016-12-06  11.601213     44\n",
      "10   B     Y 2017-08-28  28.058070      6\n",
      "89   C     W 2017-03-27  66.801608     99\n",
      "52   D     Y 2017-07-31        NaN     85\n",
      "87   C     X 2017-05-12  66.801608     69\n",
      "70   A     Z 2017-03-08  50.774371     66\n",
      "57   C     Y 2017-04-24  66.801608     83\n",
      "6    B     Y 2016-09-03  28.058070     98\n",
      "77   D     X 2017-06-06  11.601213     25\n",
      "38   C     X 2016-08-19  66.801608     79\n"
     ]
    }
   ],
   "source": [
    "storeSales.loc[np.random.choice([True, False], storeSales.shape[0], p = [.05, .95]), 'PRICE'] = np.nan\n",
    "print storeSales.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sales per STORE per DAY:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STORE  DAY       \n",
       "Z      2017-08-13    62\n",
       "Y      2016-06-10    26\n",
       "       2017-07-31    85\n",
       "X      2016-12-06    44\n",
       "       2016-07-15    31\n",
       "Name: SALES, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales.groupby(['STORE', 'DAY'])['SALES'].sum().sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Average sales of store X__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SKU\n",
       "A    45.800000\n",
       "B    22.500000\n",
       "C    57.000000\n",
       "D    54.727273\n",
       "Name: SALES, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales[storeSales['STORE'] == 'X'].groupby('SKU')['SALES'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------\n",
    "To answer time queries we need the .dt accessor of Series objects with datetime dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales['DAY'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "      <th>SALES</th>\n",
       "      <th>YEAR_WEEK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STORE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>37.716651</td>\n",
       "      <td>62.666667</td>\n",
       "      <td>201710.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>44.987891</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>201703.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>56.116783</td>\n",
       "      <td>56.750000</td>\n",
       "      <td>201711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>31.187792</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>201737.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PRICE      SALES      YEAR_WEEK\n",
       "STORE                                     \n",
       "W      37.716651  62.666667  201710.666667\n",
       "X      44.987891  42.250000  201703.750000\n",
       "Y      56.116783  56.750000  201711.000000\n",
       "Z      31.187792  41.000000  201737.500000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Monday = 0, Sunday = 6\n",
    "storeSales.groupby(storeSales['DAY'].dt.dayofweek)['SALES'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color: red\"> Exercise 1 </span>##\n",
    "Find the average sales by store on Saturdays"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load -s pandas1 solutions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "We can compute more advanced aggregations using .groupby with function objects:  \n",
    "E.g to compute the sum of sales per week and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAY\n",
      "201701      7\n",
      "201722     42\n",
      "201723     90\n",
      "201632    125\n",
      "201626    119\n",
      "201730    119\n",
      "201640     33\n",
      "201652     61\n",
      "201620     36\n",
      "201717    236\n",
      "Name: SALES, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "yearWeekAsInts = lambda tseries_: tseries_.year * 100 + tseries_.week\n",
    "salesByWeek = storeSales.groupby(yearWeekAsInts(storeSales['DAY'].dt))['SALES'].sum()\n",
    "print salesByWeek.sort_index().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute more complex aggregations I would rather create a column for yearWeeks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR_WEEK  STORE\n",
      "201647     X        25\n",
      "201732     Z        62\n",
      "201735     Z        44\n",
      "201640     Z        33\n",
      "201620     X        36\n",
      "201643     Y        39\n",
      "201752     Y        72\n",
      "201638     X        13\n",
      "201625     Z        73\n",
      "201630     Y        89\n",
      "Name: SALES, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "storeSales['YEAR_WEEK'] = yearWeekAsInts(storeSales['DAY'].dt)\n",
    "print storeSales.groupby(['YEAR_WEEK', 'STORE'])['SALES'].sum().sort_index().sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

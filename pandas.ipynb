{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLTrain logo](https://mltrain.cc/wp-content/uploads/2017/11/mltrain_logo-4.png \"MLTrain logo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .container {width: 90% !important} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> .CodeMirror {font-size: 10.5pt !important} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> div.cell.selected{border-left-width: 5px !important}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       "    .text_cell_render {\n",
       "        font-family: \"roboto condensed\"; \n",
       "        line-height: 145%; \n",
       "        font-size: 13pt} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       "    .CodeMirror {font-size: large} \n",
       "    .output_area {font-size: large} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> MathJax.Hub.Config {\n",
       "  \"HTML-CSS\": {\n",
       "    preferredFont: \"Tex\"}}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!wget -q -O changeNBLayout.py https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/changeNBLayout.py\n",
    "%run changeNBLayout.py\n",
    "# %run ../PfBDAaML/changeNBLayout.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "The pandas library implements the basic machinery for handling in-memory tabular data with Python.  \n",
    "It is a large library. Contains >600 methods, attributes and functions.  \n",
    "The online documentation of the current version (0.21) is available at https://pandas.pydata.org/pandas-docs/stable/overview.html.  \n",
    "  \n",
    "The core data structures in Pandas are the __Series, DataFrame and Index objects__.  \n",
    "You should think of Series and DataFrames as fact tables (ie with named and typed columns) and Indices as Dimensions with hierarchies.  \n",
    "  \n",
    "Pandas' methods and funtions permit standard __dimensional analysis__ (slicing, dicing and pivoting). Moreover Pandas provides a comprehensive set of analytical functions for __group transforms and ranking__.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBS player stats: \n",
      "                Name                   Team  Number Position   Age Height  Weight        College     Salary\n",
      "225  Greivis Vasquez        Milwaukee Bucks    21.0       PG  29.0    6-6   217.0       Maryland  6600000.0\n",
      "112  Marcelo Huertas     Los Angeles Lakers     9.0       PG  33.0    6-3   200.0            NaN   525093.0\n",
      "92        Jeff Ayres   Los Angeles Clippers    19.0       PF  29.0    6-9   250.0  Arizona State   111444.0\n",
      "245     Corey Brewer        Houston Rockets    33.0       SG  30.0    6-9   186.0        Florida  8229375.0\n",
      "415       Randy Foye  Oklahoma City Thunder     6.0       SG  32.0    6-4   213.0      Villanova  3135000.0\n",
      " \n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management             Team\n",
      "706       Todd    Male 1993-07-04 2017-11-22 18:53:00  128175   18.473              True              NaN\n",
      "756    Stephen    Male 1984-10-21 2017-11-22 06:26:00  121816   10.615              True     Distribution\n",
      "466     Walter    Male 2007-08-04 2017-11-22 13:59:00   58789    5.461             False            Sales\n",
      "37       Linda  Female 1981-10-19 2017-11-22 20:49:00   57427    9.557              True  Client Services\n",
      "578     Amanda  Female 1982-03-17 2017-11-22 23:46:00  107111    1.438              True          Product\n"
     ]
    }
   ],
   "source": [
    "from os import linesep as endl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Adjust Pandas layout options\n",
    "pd.set_option('display.width', 124)\n",
    "\n",
    "! wget -q -O nba.csv https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/nba.csv\n",
    "nba = pd.read_csv('nba.csv')\n",
    "print 'NBS player stats:', endl, nba.sample(5)\n",
    "\n",
    "# ! wget -q -O employees.csv https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/employees.csv\n",
    "emp = pd.read_csv(\"employees.csv\", parse_dates = [\"Start Date\", \"Last Login Time\"])\n",
    "print '', endl, emp.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introspection methods and attributes #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes have quite a few object attributes for __introspection__ and convenience methods for querying their __content__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print first 5 rows \n",
      "            Name            Team  Number Position   Age Height  Weight            College     Salary\n",
      "0  Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0              Texas  7730337.0\n",
      "1    Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0          Marquette  6796117.0\n",
      "2   John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0  Boston University        NaN\n",
      "3    R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0      Georgia State  1148640.0\n",
      "4  Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0                NaN  5000000.0\n",
      "\n",
      "Print 5 last rows \n",
      "             Name       Team  Number Position   Age Height  Weight College     Salary\n",
      "453  Shelvin Mack  Utah Jazz     8.0       PG  26.0    6-3   203.0  Butler  2433333.0\n",
      "454     Raul Neto  Utah Jazz    25.0       PG  24.0    6-1   179.0     NaN   900000.0\n",
      "455  Tibor Pleiss  Utah Jazz    21.0        C  26.0    7-3   256.0     NaN  2900000.0\n",
      "456   Jeff Withey  Utah Jazz    24.0        C  26.0    7-0   231.0  Kansas   947276.0\n",
      "457           NaN        NaN     NaN      NaN   NaN    NaN     NaN     NaN        NaN\n",
      "\n",
      "A random sample of 5 rows \n",
      "                   Name                    Team  Number Position   Age Height  Weight       College      Salary\n",
      "34        Jose Calderon         New York Knicks     3.0       PG  34.0    6-3   200.0           NaN   7402812.0\n",
      "28         Donald Sloan           Brooklyn Nets    15.0       PG  28.0    6-3   205.0     Texas A&M    947276.0\n",
      "339          Chris Bosh              Miami Heat     1.0       PF  32.0   6-11   235.0  Georgia Tech  22192730.0\n",
      "427     Cliff Alexander  Portland Trail Blazers    34.0       PF  20.0    6-8   240.0        Kansas    525093.0\n",
      "410  Karl-Anthony Towns  Minnesota Timberwolves    32.0        C  20.0    7-0   244.0      Kentucky   5703600.0\n",
      "\n",
      "Column types \n",
      "Name         object\n",
      "Team         object\n",
      "Number      float64\n",
      "Position     object\n",
      "Age         float64\n",
      "Height       object\n",
      "Weight      float64\n",
      "College      object\n",
      "Salary      float64\n",
      "dtype: object\n",
      "\n",
      "column names \n",
      "Index([u'Name', u'Team', u'Number', u'Position', u'Age', u'Height', u'Weight', u'College', u'Salary'], dtype='object')\n",
      "\n",
      "The index object \n",
      "RangeIndex(start=0, stop=458, step=1)\n",
      "\n",
      "DataFrame values as array \n",
      "[['Avery Bradley' 'Boston Celtics' 0.0 ..., 180.0 'Texas' 7730337.0]\n",
      " ['Jae Crowder' 'Boston Celtics' 99.0 ..., 235.0 'Marquette' 6796117.0]\n",
      " ['John Holland' 'Boston Celtics' 30.0 ..., 205.0 'Boston University' nan]\n",
      " ..., \n",
      " ['Tibor Pleiss' 'Utah Jazz' 21.0 ..., 256.0 nan 2900000.0]\n",
      " ['Jeff Withey' 'Utah Jazz' 24.0 ..., 231.0 'Kansas' 947276.0]\n",
      " [nan nan nan ..., nan nan nan]]\n",
      "\n",
      "Shape \n",
      "(458, 9)\n",
      "\n",
      "Number of elements \n",
      "4122\n",
      "\n",
      "Basic statistics \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 458 entries, 0 to 457\n",
      "Data columns (total 9 columns):\n",
      "Name        457 non-null object\n",
      "Team        457 non-null object\n",
      "Number      457 non-null float64\n",
      "Position    457 non-null object\n",
      "Age         457 non-null float64\n",
      "Height      457 non-null object\n",
      "Weight      457 non-null float64\n",
      "College     373 non-null object\n",
      "Salary      446 non-null float64\n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 32.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print 'Print first 5 rows', endl, nba.head(5)\n",
    "print endl, 'Print 5 last rows', endl, nba.tail()\n",
    "print endl, 'A random sample of 5 rows', endl, nba.sample(5)\n",
    "print endl, 'Column types', endl, nba.dtypes\n",
    "print endl, 'column names', endl, nba.columns\n",
    "print endl, 'The index object', endl, nba.index\n",
    "print endl, 'DataFrame values as array', endl, nba.values\n",
    "print endl, 'Shape', endl, nba.shape\n",
    "print endl, 'Number of elements', endl, nba.size\n",
    "print endl, 'Basic statistics', endl, nba.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Column types__ can be set programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before type-setting: \n",
      "First Name                   object\n",
      "Gender                       object\n",
      "Start Date           datetime64[ns]\n",
      "Last Login Time      datetime64[ns]\n",
      "Salary                        int64\n",
      "Bonus %                     float64\n",
      "Senior Management            object\n",
      "Team                         object\n",
      "dtype: object\n",
      "\n",
      "After type-setting \n",
      "First Name                   object\n",
      "Gender                     category\n",
      "Start Date           datetime64[ns]\n",
      "Last Login Time      datetime64[ns]\n",
      "Salary                        int64\n",
      "Bonus %                     float64\n",
      "Senior Management              bool\n",
      "Team                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print 'Before type-setting:', endl, emp.dtypes\n",
    "\n",
    "# Change types programmatically\n",
    "emp[\"Senior Management\"] = emp[\"Senior Management\"].astype('bool')\n",
    "emp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n",
    "\n",
    "print endl, 'After type-setting', endl, emp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary ctor:\n",
      "   pop   state  year\n",
      "0  1.5    Ohio  2000\n",
      "1  1.7    Ohio  2001\n",
      "2  3.6    Ohio  2002\n",
      "3  2.4  Nevada  2001\n",
      "4  2.9  Nevada  2002\n",
      "\n",
      "If you specify a different order in \"columns\" the df will be arranged properly:\n",
      "   year   state  pop\n",
      "0  2000    Ohio  1.5\n",
      "1  2001    Ohio  1.7\n",
      "2  2002    Ohio  3.6\n",
      "3  2001  Nevada  2.4\n",
      "4  2002  Nevada  2.9\n",
      "\n",
      "Non-existing columns fill the DataFrame with nulls:\n",
      "       year   state  pop debt\n",
      "one    2000    Ohio  1.5  NaN\n",
      "two    2001    Ohio  1.7  NaN\n",
      "three  2002    Ohio  3.6  NaN\n",
      "four   2001  Nevada  2.4  NaN\n",
      "five   2002  Nevada  2.9  NaN\n",
      "\n",
      "A nested dict creates column and index objects:\n",
      "      Nevada  Ohio\n",
      "2000     NaN   1.5\n",
      "2001     2.4   1.7\n",
      "2002     2.9   3.6\n",
      "\n",
      "Index and columns can be named:\n",
      "colNames    year state   pop\n",
      "ixNames                     \n",
      "one         Ohio   1.5  2000\n",
      "two         Ohio   1.7  2001\n",
      "three       Ohio   3.6  2002\n",
      "four      Nevada   2.4  2001\n",
      "five      Nevada   2.9  2002\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "    'year': [2000, 2001, 2002, 2001, 2002],\n",
    "    'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "\n",
    "print 'Dictionary ctor:'\n",
    "print frame\n",
    "\n",
    "print endl, 'If you specify a different order in \"columns\" the df will be arranged properly:'\n",
    "print pd.DataFrame(data, columns = ['year', 'state', 'pop'])\n",
    "\n",
    "frame2 = pd.DataFrame(\n",
    "    data, \n",
    "    columns = ['year', 'state', 'pop', 'debt'],\n",
    "    index = ['one', 'two', 'three', 'four', 'five'])\n",
    "print endl, 'Non-existing columns fill the DataFrame with nulls:'\n",
    "print frame2\n",
    "\n",
    "pop = {'Nevada': {2001: 2.4, 2002: 2.9}, 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}\n",
    "frame3 = pd.DataFrame(pop)\n",
    "\n",
    "print endl, 'A nested dict creates column and index objects:'\n",
    "print frame3\n",
    "\n",
    "listT = lambda _: np.array(_).T\n",
    "frame4 = pd.DataFrame(\n",
    "    data = listT(data.values()), \n",
    "    index = ['one', 'two', 'three', 'four', 'five'], \n",
    "    columns = ['year', 'state', 'pop'])\n",
    "\n",
    "frame4.index.name = 'ixNames'\n",
    "frame4.columns.name = 'colNames'\n",
    "\n",
    "print endl, 'Index and columns can be named:'\n",
    "print frame4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "# Projection and selection #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio             4\n",
      "Colorado         1\n",
      "Utah             6\n",
      "New York         9\n",
      "Atlanta          5\n",
      "San Francisco    6\n",
      "Name: one, dtype: int64\n",
      "               one  two\n",
      "Ohio             4    0\n",
      "Colorado         1    7\n",
      "Utah             6    3\n",
      "New York         9    2\n",
      "Atlanta          5    8\n",
      "San Francisco    6    2\n",
      "               one  two  four\n",
      "Ohio             4    0     5\n",
      "Colorado         1    7     8\n",
      "Utah             6    3     7\n",
      "New York         9    2     0\n",
      "Atlanta          5    8     5\n",
      "San Francisco    6    2     0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "    np.random.choice(10, 24).reshape((6, 4)),\n",
    "    index = ['Ohio', 'Colorado', 'Utah', 'New York', 'Atlanta', 'San Francisco'],\n",
    "    columns = ['one', 'two', 'three', 'four'])\n",
    "\n",
    "# Projections\n",
    "print data['one']\n",
    "print data[['one', 'two']]\n",
    "print data[[col for col in data.columns if 'o' in col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by index ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two      8\n",
       "three    1\n",
       "Name: Atlanta, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selection by index label\n",
    "data.loc['Ohio']\n",
    "data.loc['Ohio':'Utah']\n",
    "data.loc[['Ohio', 'New York']]\n",
    "\n",
    "# Integer selection\n",
    "data.iloc[2:4]\n",
    "data.iloc[::-1]\n",
    "data[2:4]\n",
    "\n",
    "\n",
    "# Simultaneous selection by label and projection\n",
    "data.loc['Atlanta', ['two', 'three']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean and relational selections ###\n",
    "\n",
    "We can specify __index__ shards (position lists and ranges) by boolean or relational expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management       Team\n",
      "586       Rose  Female 2004-10-30 2017-11-22 16:34:00   56961    7.585             False  Marketing\n",
      "860    Phillip    Male 1984-10-07 2017-11-22 11:05:00   36837   14.660             False  Marketing\n",
      "\n",
      "    First Name Gender Start Date     Last Login Time  Salary  Bonus % Senior Management   Team\n",
      "739     Carlos   Male 1981-01-25 2017-11-22 10:00:00  138598   14.737             False  Sales\n",
      "787      Kevin   Male 2005-07-01 2017-11-22 15:22:00  141498    4.135              True  Sales\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management     Team\n",
      "6         Ruby  Female 1987-08-17 2017-11-22 16:20:00   65476   10.012              True  Product\n",
      "548     Janice  Female 1984-01-02 2017-11-22 21:06:00   41190    3.311              True    Sales\n",
      "\n",
      "    First Name Gender Start Date     Last Login Time  Salary  Bonus % Senior Management       Team\n",
      "722     Joshua   Male 1997-06-27 2017-11-22 15:23:00   95003    5.197              True  Marketing\n",
      "404      Sarah    NaN 1990-07-20 2017-11-22 22:49:00  109980    8.860             False      Sales\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management             Team\n",
      "968     Louise  Female 1995-03-27 2017-11-22 22:27:00   43050   11.671             False     Distribution\n",
      "662  Katherine  Female 2000-12-19 2017-11-22 01:40:00   41643    4.659              True     Distribution\n",
      "82      Steven    Male 1980-03-30 2017-11-22 21:20:00   35095    8.379              True  Client Services\n",
      "711      Karen  Female 2014-01-09 2017-11-22 22:09:00   46478   16.552             False      Engineering\n",
      "491   Nicholas     NaN 1989-09-09 2017-11-22 19:12:00   58478    6.525              True     Distribution\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management             Team\n",
      "18       Diana  Female 1981-10-23 2017-11-22 10:27:00  132940   19.082             False  Client Services\n",
      "636    Marilyn  Female 1984-07-02 2017-11-22 16:06:00   92430    2.924             False      Engineering\n",
      "69       Irene     NaN 2015-07-14 2017-11-22 16:31:00  100863    4.382              True          Finance\n",
      "305   Margaret  Female 1993-02-06 2017-11-22 13:05:00  125220    3.733             False        Marketing\n"
     ]
    }
   ],
   "source": [
    "# Selection based on categories\n",
    "print emp[emp['Team'] == 'Marketing'].sample(2)\n",
    "print endl, emp[(emp['Gender'] == 'Male') & (emp['Team'] == 'Sales')].sample(2)\n",
    "print endl, emp[(emp['Gender'] == 'Female') & ~(emp['First Name'] == 'Mary')].sample(2)\n",
    "\n",
    "# Selection based on scalars\n",
    "print endl, emp[emp['Start Date'] > '1990-01-01'].sample(2)\n",
    "\n",
    "# a more complex condition\n",
    "print endl, emp[~emp['Team'].isin(['Marketing', 'Sales'])].sample(5, replace = False)\n",
    "\n",
    "print endl, emp[emp['Salary'].between(80000, 150000)].sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General boolean selections ###\n",
    "We can select values of a Dataframe's cells more flexibly:  \n",
    "We can use boolean masks with the shape of the frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     First Name  Gender  Start Date  Last Login Time  Salary  Bonus %  Senior Management   Team\n",
      "170       False   False        True             True   False     True              False  False\n",
      "208        True    True        True            False    True     True               True   True\n",
      "354        True    True        True            False    True    False               True   True\n",
      "154       False   False       False            False   False    False              False  False\n",
      "401        True   False        True             True    True    False               True   True\n",
      "545       False    True        True            False    True     True               True  False\n",
      "214        True    True        True             True   False     True               True   True\n",
      "144       False    True        True             True   False     True              False  False\n",
      "870       False    True        True             True    True     True               True   True\n",
      "697        True   False       False             True   False     True               True  False\n"
     ]
    }
   ],
   "source": [
    "mask = pd.DataFrame(np.random.choice([True, False], emp.shape, p = [.5, .5]), columns = emp.columns)\n",
    "print emp[mask].isnull().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .isnull and .notnull ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460    True\n",
      "961    True\n",
      "390    True\n",
      "322    True\n",
      "432    True\n",
      "Name: Team, dtype: bool\n",
      "\n",
      "First names of employees without team:\n",
      "843    NaN\n",
      "500    NaN\n",
      "38     NaN\n",
      "182    NaN\n",
      "97     NaN\n",
      "Name: First Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print emp['Team'].isnull().sample(5)\n",
    "\n",
    "print endl, 'First names of employees without team:'\n",
    "print emp['First Name'][emp['Team'].isnull()].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .unique and .nunique #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas' 'Louise' nan 'James' 'Christopher' 'Jonathan' 'Michael' 'Jeremy'\n",
      " 'Bobby' 'Edward' 'Joyce' 'Jason' 'Chris' 'Richard' 'Wanda' 'Jimmy' 'Peter'\n",
      " 'Kimberly' 'Harry' 'Carl' 'Randy' 'Donald' 'Joseph' 'Alice' 'Todd'\n",
      " 'Daniel' 'Antonio' 'Lawrence' 'Nicole' 'Charles' 'Mildred' 'Phillip'\n",
      " 'Ryan' 'Joe']\n",
      "\n",
      "34\n",
      "\n",
      "Not equal. Why? \n",
      "33\n",
      "\n",
      "Now they're equal: \n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print emp['First Name'][emp['Team'].isnull()].unique()\n",
    "\n",
    "print endl, len(emp['First Name'][emp['Team'].isnull()].unique())\n",
    "\n",
    "print endl, 'Not equal. Why?', endl, emp['First Name'][emp['Team'].isnull()].nunique()\n",
    "\n",
    "print endl, \"Now they're equal:\", endl, emp['First Name'][emp['Team'].isnull()].nunique(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sorting and ranking #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Name Gender Start Date     Last Login Time  Salary  Bonus %  Senior Management             Team\n",
      "101      Aaron   Male 2012-02-17 2017-11-21 10:20:00   61602   11.849               True        Marketing\n",
      "327      Aaron   Male 1994-01-29 2017-11-21 18:48:00   58755    5.097               True        Marketing\n",
      "440      Aaron   Male 1990-07-22 2017-11-21 14:53:00   52119   11.343               True  Client Services\n",
      "937      Aaron    NaN 1986-01-22 2017-11-21 19:39:00   63126   18.424              False  Client Services\n",
      "137       Adam   Male 2011-05-21 2017-11-21 01:45:00   95327   15.120              False     Distribution\n",
      "\n",
      "Sort by \"Start Date\" using index sorting\n",
      "\n",
      "           First Name  Gender     Last Login Time  Salary  Bonus %  Senior Management             Team\n",
      "Start Date                                                                                            \n",
      "2016-07-15      Terry     NaN 2017-11-21 00:29:00  140002   19.490               True        Marketing\n",
      "2016-06-16       Tina  Female 2017-11-21 19:47:00  100705   16.961               True        Marketing\n",
      "2016-06-05    Lillian  Female 2017-11-21 06:09:00   59414    1.256              False          Product\n",
      "2016-05-24        NaN    Male 2017-11-21 21:17:00   76409    7.008               True     Distribution\n",
      "2016-05-12    Lillian     NaN 2017-11-21 15:43:00   64164   17.612              False  Human Resources\n"
     ]
    }
   ],
   "source": [
    "# To sort by the values of one or more columns use sort_values method\n",
    "print emp.sort_values(by = 'First Name', na_position = 'last').head(5)\n",
    "\n",
    "# Create an index by which to sort\n",
    "print endl, 'Sort by \"Start Date\" using index sorting'\n",
    "_0 = emp.set_index(keys = 'Start Date', drop = True)\n",
    "print endl, _0.sort_index(ascending = False, na_position = 'last').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rank` will assign integers to values according to their ordered position.  \n",
    "The ranks can be contiguous or not according to the ranking method. Groups of equal values are always assigned the same rank.  \n",
    "`average` assigns to each equi-valued group the average of their sort-index.  \n",
    "  \n",
    "__NB:__ The ranks of the resulting set are not sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  1  4\n",
      "1  4  1\n",
      "2  4  2\n",
      "3  4  0\n",
      "4  4  4\n",
      "5  0  3\n",
      "6  1  2\n",
      "7  3  0\n",
      "8  1  1\n",
      "9  1  3\n",
      "\n",
      "Default ranks of first column elements 0    8.5\n",
      "1    2.0\n",
      "2    8.5\n",
      "3    2.0\n",
      "4    8.5\n",
      "5    6.0\n",
      "6    4.5\n",
      "7    4.5\n",
      "8    2.0\n",
      "9    8.5\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Dense ranking \n",
      "   0    0\n",
      "0  4  4.0\n",
      "1  0  1.0\n",
      "2  4  4.0\n",
      "3  0  1.0\n",
      "4  4  4.0\n",
      "5  3  3.0\n",
      "6  1  2.0\n",
      "7  1  2.0\n",
      "8  0  1.0\n",
      "9  4  4.0\n"
     ]
    }
   ],
   "source": [
    "# create a dummy DataFrame\n",
    "_1 = pd.DataFrame(np.random.choice(5, [10, 2]))\n",
    "print _1\n",
    "\n",
    "# Default ranking\n",
    "print endl, 'Default ranks of first column elements', df[0].rank()\n",
    "\n",
    "print endl, 'Dense ranking', endl, pd.concat([df[0], df[0].rank(method = 'dense')], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "# Groupings and transforms #\n",
    "\n",
    "Projections and selections when combined with `.groupby`, `.apply` and `.transform` methods described in the sequel, essentially constitute Panda's powerful framework for multidimensional analysis (MDA).  \n",
    "MDA supported by visualizations (an area we'll explore later) is what has been known as __Exploratory Data Analysis__, a term coined in the 70s by John Tukey, one of the prominent statisticians of our era\n",
    "\n",
    "__Quiz:__ What else is [Tukey known for](https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm)? (it dominated the electronics industry for 3 decades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset ###\n",
    "Create a Dataframe with Sales records of an imaginary retailer.  \n",
    "The retailer sells products identified by their Stock-keeping unit (SKU column) in several stores identified by their ID (STORE column).  \n",
    "Each record contains the number and the price of items (SKUs) sold in a store at a particular day.\n",
    "  \n",
    "For our case assume there're 4 SKUs, 5 stores and we have records from 01Oct2017 to 31Oct2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SKUs\n",
    "storeSales = pd.DataFrame(np.random.choice(list('ABCD'), 100), columns = ['SKU'])\n",
    "# Stores\n",
    "storeSales['STORE'] = np.random.choice(list('WXYZ'), 100)\n",
    "# Dates\n",
    "storeSales['DAY'] = np.random.choice(pd.date_range(start = dt(2017, 10, 1), end = dt(2017, 10, 31)), 100)\n",
    "#Price: \n",
    "prices = dict(zip(list('ABCD'), np.random.uniform(10, 100, 4)))\n",
    "storeSales['PRICE'] = storeSales['SKU'].map(prices)\n",
    "\n",
    "# Items sold. # Permit 0 sales on item\n",
    "storeSales['SALES'] = np.random.uniform(0, 100, 100).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permit some null prices (e.g. assume some SKUs were sold with coupons of varying markdowns)  \n",
    "__Caveat:__  \n",
    "If you try to use instead\n",
    "``` Python\n",
    "storeSales[np.random.choice([True, False], storeSales.shape[0], p = [.05, .95])]['PRICE'] = np.nan\n",
    "```\n",
    "you get a warning that 'you're trying to a ssign to an implicit copy'.  \n",
    "  \n",
    "__Quiz:__ Where's the implicit copy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SKU STORE        DAY      PRICE  SALES\n",
      "91   D     X 2017-10-08  29.675272      3\n",
      "17   A     Y 2017-10-12  70.296706     11\n",
      "69   D     W 2017-10-11  29.675272     95\n",
      "1    D     Z 2017-10-30  29.675272     87\n",
      "86   D     Z 2017-10-09  29.675272     51\n",
      "90   C     X 2017-10-14  56.171025     19\n",
      "34   A     Y 2017-10-08  70.296706     39\n",
      "35   A     W 2017-10-21  70.296706     18\n",
      "97   C     W 2017-10-09  56.171025     10\n",
      "55   D     W 2017-10-18  29.675272     75\n",
      "62   C     X 2017-10-03  56.171025     62\n",
      "67   D     Z 2017-10-07  29.675272     34\n",
      "39   C     Y 2017-10-01  56.171025     77\n",
      "70   A     Z 2017-10-23  70.296706     12\n",
      "57   C     Y 2017-10-26  56.171025     23\n",
      "59   A     Y 2017-10-03  70.296706     36\n",
      "25   D     Z 2017-10-20  29.675272     23\n",
      "10   B     Y 2017-10-05  39.044652      0\n",
      "15   B     Z 2017-10-21  39.044652     74\n",
      "84   A     Z 2017-10-01  70.296706     68\n"
     ]
    }
   ],
   "source": [
    "storeSales.loc[np.random.choice([True, False], storeSales.shape[0], p = [.05, .95]), 'PRICE'] = np.nan\n",
    "print storeSales.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sales per STORE per DAY:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STORE  DAY       \n",
       "X      2017-10-28      0\n",
       "W      2017-10-19    106\n",
       "Z      2017-10-22     22\n",
       "Y      2017-10-09     62\n",
       "Z      2017-10-20     23\n",
       "Name: SALES, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales.groupby(['STORE', 'DAY'])['SALES'].sum().sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Average sales of store X__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SKU\n",
       "A    46.800000\n",
       "B    46.500000\n",
       "C    51.200000\n",
       "D    45.636364\n",
       "Name: SALES, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales[storeSales['STORE'] == 'X'].groupby('SKU')['SALES'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------\n",
    "To answer time queries we need the .dt accessor of Series objects with datetime dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales['DAY'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY\n",
       "0    50.555556\n",
       "1    34.611111\n",
       "2    47.153846\n",
       "3    55.307692\n",
       "4    42.230769\n",
       "5    42.777778\n",
       "6    50.937500\n",
       "Name: SALES, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Monday = 0, Sunday = 6\n",
    "storeSales.groupby(storeSales['DAY'].dt.dayofweek)['SALES'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: ###\n",
    "Find the average sales on Saturdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

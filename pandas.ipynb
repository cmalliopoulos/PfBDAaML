{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLTrain logo](https://mltrain.cc/wp-content/uploads/2017/11/mltrain_logo-4.png \"MLTrain logo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    @import url('https://fonts.googleapis.com/css?family=Roboto+Condensed');\n",
       "    </style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> .container {width: 90%} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> .CodeMirror {font-size: 10.5pt !important} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style> div.cell.selected{border: 0px};</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       "    .text_cell_render {\n",
       "        font-family: \"Roboto Condensed\"; \n",
       "        line-height: 145%; \n",
       "        font-size: 14pt} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       "    .output_area {font-size: large} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !wget -q -O changeNBLayout.py https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/changeNBLayout.py\n",
    "%run changeNBLayout.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/https://www.youtube.com/watch?v=XDAnFZqJDvI&list=PLIivdWyY5sqJxnwJhe3etaK7utrBiPBQ2&index=12\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f581055c510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('https://www.youtube.com/watch?v=XDAnFZqJDvI&list=PLIivdWyY5sqJxnwJhe3etaK7utrBiPBQ2&index=12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas library implements the basic machinery for handling in-memory tabular data with Python.  \n",
    "It is a large library. Contains >600 methods, attributes and functions.  \n",
    "The online documentation of the current version (0.21) is available at https://pandas.pydata.org/pandas-docs/stable/overview.html.  \n",
    "  \n",
    "The core data structures in Pandas are the __Series, DataFrame and Index objects__.  \n",
    "You should think of Series and DataFrames as fact tables (ie with named and typed columns) and Indices as Dimensions with hierarchies.  \n",
    "  \n",
    "Pandas' methods and funtions permit standard __dimensional analysis__ (slicing, dicing and pivoting). Moreover Pandas provides a comprehensive set of analytical functions for __group transforms and ranking__.  \n",
    "  \n",
    "__Pandas__ stands for __Pan__el __Da__ta.  \n",
    "It was developed as a way to programmaticaly do EXCEL-type calculations however it resembles more to Microsoft's __Power Pivot__  \n",
    "due to its rich type system, visualization and tabular processing capabilities.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import linesep as endl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Adjust Pandas layout options\n",
    "pd.set_option('display.width', 124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBS player stats: \n",
      "                         Name                  Team  Number Position   Age Height  Weight     College      Salary\n",
      "451             Chris Johnson             Utah Jazz    23.0       SF  26.0    6-6   206.0      Dayton    981348.0\n",
      "37               Jerian Grant       New York Knicks    13.0       PG  23.0    6-4   195.0  Notre Dame   1572360.0\n",
      "252            Terrence Jones       Houston Rockets     6.0       PF  24.0    6-9   252.0    Kentucky   2489530.0\n",
      "99   Luc Richard Mbah a Moute  Los Angeles Clippers    12.0       PF  29.0    6-8   230.0        UCLA    947276.0\n",
      "96              Blake Griffin  Los Angeles Clippers    32.0       PF  27.0   6-10   251.0    Oklahoma  18907726.0\n"
     ]
    }
   ],
   "source": [
    "! wget -q -O nba.csv https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/nba.csv\n",
    "nba = pd.read_csv('nba.csv')\n",
    "print 'NBS player stats:', endl, nba.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus % Senior Management                  Team\n",
      "841       Ruby  Female 2006-08-13 2017-11-29 18:27:00   48354   19.501             False  Business Development\n",
      "973    Russell    Male 2013-05-10 2017-11-29 23:08:00  137359   11.105             False  Business Development\n",
      "152       Ruth  Female 1999-08-19 2017-11-29 04:03:00  129297    8.067              True       Client Services\n",
      "771      Peter    Male 1991-05-22 2017-11-29 01:39:00  102577   12.026              True               Product\n",
      "456    Deborah     NaN 1983-02-03 2017-11-29 23:38:00  101457    6.662             False           Engineering\n"
     ]
    }
   ],
   "source": [
    "! wget -q -O employees.csv https://raw.githubusercontent.com/cmalliopoulos/PfBDAaML/master/employees.csv\n",
    "emp = pd.read_csv(\"employees.csv\", parse_dates = [\"Start Date\", \"Last Login Time\"])\n",
    "print '', endl, emp.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introspection methods and attributes #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes have quite a few object attributes for __introspection__ and convenience methods for querying their __content__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print first 5 rows \n",
      "            Name            Team  Number Position   Age Height  Weight            College     Salary\n",
      "0  Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0              Texas  7730337.0\n",
      "1    Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0          Marquette  6796117.0\n",
      "2   John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0  Boston University        NaN\n",
      "3    R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0      Georgia State  1148640.0\n",
      "4  Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0                NaN  5000000.0\n"
     ]
    }
   ],
   "source": [
    "print 'Print first 5 rows', endl, nba.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print 5 last rows \n",
      "             Name       Team  Number Position   Age Height  Weight College     Salary\n",
      "453  Shelvin Mack  Utah Jazz     8.0       PG  26.0    6-3   203.0  Butler  2433333.0\n",
      "454     Raul Neto  Utah Jazz    25.0       PG  24.0    6-1   179.0     NaN   900000.0\n",
      "455  Tibor Pleiss  Utah Jazz    21.0        C  26.0    7-3   256.0     NaN  2900000.0\n",
      "456   Jeff Withey  Utah Jazz    24.0        C  26.0    7-0   231.0  Kansas   947276.0\n",
      "457           NaN        NaN     NaN      NaN   NaN    NaN     NaN     NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "print 'Print 5 last rows', endl, nba.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random sample of 5 rows \n",
      "                       Name                    Team  Number Position   Age Height  Weight   College     Salary\n",
      "32   Thanasis Antetokounmpo         New York Knicks    43.0       SF  23.0    6-7   205.0       NaN    30888.0\n",
      "4             Jonas Jerebko          Boston Celtics     8.0       PF  29.0   6-10   231.0       NaN  5000000.0\n",
      "88        Marreese Speights   Golden State Warriors     5.0        C  28.0   6-10   255.0   Florida  3815000.0\n",
      "457                     NaN                     NaN     NaN      NaN   NaN    NaN     NaN       NaN        NaN\n",
      "410      Karl-Anthony Towns  Minnesota Timberwolves    32.0        C  20.0    7-0   244.0  Kentucky  5703600.0\n"
     ]
    }
   ],
   "source": [
    "print 'A random sample of 5 rows', endl, nba.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column types \n",
      "Name         object\n",
      "Team         object\n",
      "Number      float64\n",
      "Position     object\n",
      "Age         float64\n",
      "Height       object\n",
      "Weight      float64\n",
      "College      object\n",
      "Salary      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print 'Column types', endl, nba.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names \n",
      "Index([u'Name', u'Team', u'Number', u'Position', u'Age', u'Height', u'Weight', u'College', u'Salary'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print 'column names', endl, nba.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index object \n",
      "RangeIndex(start=0, stop=458, step=1)\n"
     ]
    }
   ],
   "source": [
    "print 'The index object', endl, nba.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame values as array \n",
      "[['Avery Bradley' 'Boston Celtics' 0.0 ..., 180.0 'Texas' 7730337.0]\n",
      " ['Jae Crowder' 'Boston Celtics' 99.0 ..., 235.0 'Marquette' 6796117.0]\n",
      " ['John Holland' 'Boston Celtics' 30.0 ..., 205.0 'Boston University' nan]\n",
      " ..., \n",
      " ['Tibor Pleiss' 'Utah Jazz' 21.0 ..., 256.0 nan 2900000.0]\n",
      " ['Jeff Withey' 'Utah Jazz' 24.0 ..., 231.0 'Kansas' 947276.0]\n",
      " [nan nan nan ..., nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "print 'DataFrame values as array', endl, nba.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape \n",
      "(458, 9)\n"
     ]
    }
   ],
   "source": [
    "print 'Shape', endl, nba.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of elements \n",
      "4122\n"
     ]
    }
   ],
   "source": [
    "print endl, 'Number of elements', endl, nba.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 458 entries, 0 to 457\n",
      "Data columns (total 9 columns):\n",
      "Name        457 non-null object\n",
      "Team        457 non-null object\n",
      "Number      457 non-null float64\n",
      "Position    457 non-null object\n",
      "Age         457 non-null float64\n",
      "Height      457 non-null object\n",
      "Weight      457 non-null float64\n",
      "College     373 non-null object\n",
      "Salary      446 non-null float64\n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 32.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print 'Basic statistics', endl, nba.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Value counts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Orleans Pelicans    19\n",
      "Memphis Grizzlies       18\n",
      "Milwaukee Bucks         16\n",
      "New York Knicks         16\n",
      "Denver Nuggets          15\n",
      "Name: Team, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print nba.Team.value_counts(sort = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Column types__ can be set programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before type-setting: \n",
      "First Name                   object\n",
      "Gender                       object\n",
      "Start Date           datetime64[ns]\n",
      "Last Login Time      datetime64[ns]\n",
      "Salary                        int64\n",
      "Bonus %                     float64\n",
      "Senior Management            object\n",
      "Team                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print 'Before type-setting:', endl, emp.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After type-setting \n",
      "First Name                   object\n",
      "Gender                     category\n",
      "Start Date           datetime64[ns]\n",
      "Last Login Time      datetime64[ns]\n",
      "Salary                        int64\n",
      "Bonus %                     float64\n",
      "Senior Management              bool\n",
      "Team                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Change types programmatically\n",
    "emp[\"Senior Management\"] = emp[\"Senior Management\"].astype('bool')\n",
    "emp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n",
    "\n",
    "print endl, 'After type-setting', endl, emp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary ctor:\n",
      "   pop   state  year\n",
      "0  1.5    Ohio  2000\n",
      "1  1.7    Ohio  2001\n",
      "2  3.6    Ohio  2002\n",
      "3  2.4  Nevada  2001\n",
      "4  2.9  Nevada  2002\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "    'year': [2000, 2001, 2002, 2001, 2002],\n",
    "    'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "\n",
    "print 'Dictionary ctor:'\n",
    "print pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you specify a different order in \"columns\" the df will be arranged properly:\n",
      "   year   state  pop\n",
      "0  2000    Ohio  1.5\n",
      "1  2001    Ohio  1.7\n",
      "2  2002    Ohio  3.6\n",
      "3  2001  Nevada  2.4\n",
      "4  2002  Nevada  2.9\n"
     ]
    }
   ],
   "source": [
    "print endl, 'If you specify a different order in \"columns\" the df will be arranged properly:'\n",
    "print pd.DataFrame(data, columns = ['year', 'state', 'pop'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-existing columns fill the DataFrame with nulls:\n",
      "       year   state  pop debt\n",
      "one    2000    Ohio  1.5  NaN\n",
      "two    2001    Ohio  1.7  NaN\n",
      "three  2002    Ohio  3.6  NaN\n",
      "four   2001  Nevada  2.4  NaN\n",
      "five   2002  Nevada  2.9  NaN\n"
     ]
    }
   ],
   "source": [
    "frame2 = pd.DataFrame(\n",
    "    data, \n",
    "    columns = ['year', 'state', 'pop', 'debt'],\n",
    "    index = ['one', 'two', 'three', 'four', 'five'])\n",
    "print 'Non-existing columns fill the DataFrame with nulls:'\n",
    "print frame2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A nested dict creates column and index objects:\n",
      "      Nevada  Ohio\n",
      "2000     NaN   1.5\n",
      "2001     2.4   1.7\n",
      "2002     2.9   3.6\n"
     ]
    }
   ],
   "source": [
    "pop = {'Nevada': {2001: 2.4, 2002: 2.9}, 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}\n",
    "frame3 = pd.DataFrame(pop)\n",
    "\n",
    "print 'A nested dict creates column and index objects:'\n",
    "print frame3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index and columns can be named:\n",
      "colNames    year state   pop\n",
      "ixNames                     \n",
      "one         Ohio   1.5  2000\n",
      "two         Ohio   1.7  2001\n",
      "three       Ohio   3.6  2002\n",
      "four      Nevada   2.4  2001\n",
      "five      Nevada   2.9  2002\n"
     ]
    }
   ],
   "source": [
    "listT = lambda _: np.array(_).T\n",
    "\n",
    "frame4 = pd.DataFrame(\n",
    "    data = listT(data.values()), \n",
    "    index = ['one', 'two', 'three', 'four', 'five'], \n",
    "    columns = ['year', 'state', 'pop'])\n",
    "\n",
    "frame4.index.name = 'ixNames'\n",
    "frame4.columns.name = 'colNames'\n",
    "\n",
    "print 'Index and columns can be named:'\n",
    "print frame4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "# Projection and selection #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio             9\n",
      "Colorado         6\n",
      "Utah             2\n",
      "New York         5\n",
      "Atlanta          0\n",
      "San Francisco    3\n",
      "Name: one, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "    np.random.choice(10, 24).reshape((6, 4)),\n",
    "    index = ['Ohio', 'Colorado', 'Utah', 'New York', 'Atlanta', 'San Francisco'],\n",
    "    columns = ['one', 'two', 'three', 'four'])\n",
    "\n",
    "# Projections\n",
    "print data['one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               one  two\n",
      "Ohio             9    0\n",
      "Colorado         6    6\n",
      "Utah             2    1\n",
      "New York         5    0\n",
      "Atlanta          0    8\n",
      "San Francisco    3    3\n"
     ]
    }
   ],
   "source": [
    "print data[['one', 'two']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               one  two  four\n",
      "Ohio             9    0     5\n",
      "Colorado         6    6     1\n",
      "Utah             2    1     5\n",
      "New York         5    0     0\n",
      "Atlanta          0    8     9\n",
      "San Francisco    3    3     3\n"
     ]
    }
   ],
   "source": [
    "print data[[col for col in data.columns if 'o' in col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by index ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two      8\n",
       "three    3\n",
       "Name: Atlanta, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selection by index label\n",
    "data.loc['Ohio']\n",
    "data.loc['Ohio':'Utah']\n",
    "data.loc[['Ohio', 'New York']]\n",
    "\n",
    "# Integer selection\n",
    "data.iloc[2:4]\n",
    "data.iloc[::-1]\n",
    "data[2:4]\n",
    "\n",
    "\n",
    "# Simultaneous selection by label and projection\n",
    "data.loc['Atlanta', ['two', 'three']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean and relational selections ###\n",
    "\n",
    "We can specify __index__ shards (position lists and ranges) by boolean or relational expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus %  Senior Management       Team\n",
      "947        NaN    Male 2012-07-30 2017-11-27 15:07:00  107351    5.329               True  Marketing\n",
      "730     Nicole  Female 2009-04-26 2017-11-27 00:40:00   66047   18.674               True  Marketing\n"
     ]
    }
   ],
   "source": [
    "# Selection based on categories\n",
    "print emp[emp['Team'] == 'Marketing'].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Name Gender Start Date     Last Login Time  Salary  Bonus %  Senior Management   Team\n",
      "371      Larry   Male 2003-08-27 2017-11-27 13:00:00   91133    5.140              False  Sales\n",
      "202      Roger   Male 1982-11-08 2017-11-27 02:32:00  140558    5.084               True  Sales\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus %  Senior Management       Team\n",
      "361   Margaret  Female 2014-05-05 2017-11-27 06:01:00   55044    4.078              False      Sales\n",
      "43     Marilyn  Female 1980-12-07 2017-11-27 03:16:00   73524    5.207               True  Marketing\n"
     ]
    }
   ],
   "source": [
    "print emp[(emp['Gender'] == 'Male') & (emp['Team'] == 'Sales')].sample(2)\n",
    "print endl, emp[(emp['Gender'] == 'Female') & ~(emp['First Name'] == 'Mary')].sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Name Gender Start Date     Last Login Time  Salary  Bonus %  Senior Management             Team\n",
      "70        Todd    NaN 2003-06-10 2017-11-27 14:26:00   84692    6.617              False  Client Services\n",
      "463       Jose   Male 2002-07-11 2017-11-27 09:15:00   59862    3.269              False          Product\n"
     ]
    }
   ],
   "source": [
    "# Selection based on scalars\n",
    "print emp[emp['Start Date'] > '1990-01-01'].sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus %  Senior Management             Team\n",
      "289    Jessica  Female 1985-09-27 2017-11-27 13:35:00   75145    6.388               True            Legal\n",
      "966      Louis    Male 2011-08-16 2017-11-27 17:19:00   93022    9.146               True  Human Resources\n",
      "879        Amy  Female 2009-05-20 2017-11-27 06:26:00   75415   19.132              False  Client Services\n",
      "\n",
      "    First Name  Gender Start Date     Last Login Time  Salary  Bonus %  Senior Management                  Team\n",
      "725     Jeremy    Male 1991-05-19 2017-11-27 13:40:00  131513    1.876               True               Finance\n",
      "219      Billy    Male 1995-03-13 2017-11-27 12:05:00  120444    7.768               True               Finance\n",
      "164       Mary  Female 1999-08-13 2017-11-27 01:03:00  134645   18.197              False  Business Development\n"
     ]
    }
   ],
   "source": [
    "# a more complex condition\n",
    "print endl, emp[~emp['Team'].isin(['Marketing', 'Sales'])].sample(3, replace = False)\n",
    "print endl, emp[emp['Salary'].between(80000, 150000)].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More general selections ###\n",
    "With Dataframes of integral types more general selections are possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of floats: \n",
      "          0         1         2         3         4\n",
      "0 -2.202541 -0.223003  0.158628  0.703146  1.529454\n",
      "1  0.665455 -0.373617  0.627859  2.034397 -0.075145\n",
      "2 -0.815562 -0.107887  1.090448 -0.882143  0.560488\n",
      "3  0.188105  1.804585 -2.377244 -1.538447 -0.493399\n",
      "4  0.062000 -1.273610  1.415440  0.314913  0.123493\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 5))\n",
    "print 'Dataframe of floats:', endl, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean mask \n",
      "       0      1      2      3      4\n",
      "0  False  False  False   True   True\n",
      "1   True  False   True   True  False\n",
      "2  False  False   True  False   True\n",
      "3  False   True  False  False  False\n",
      "4  False  False   True  False  False\n"
     ]
    }
   ],
   "source": [
    "mask = (df > .5)\n",
    "print 'Boolean mask', endl, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying mask to df: \n",
      "          0         1         2         3         4\n",
      "0       NaN       NaN       NaN  0.703146  1.529454\n",
      "1  0.665455       NaN  0.627859  2.034397       NaN\n",
      "2       NaN       NaN  1.090448       NaN  0.560488\n",
      "3       NaN  1.804585       NaN       NaN       NaN\n",
      "4       NaN       NaN  1.415440       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "print 'Applying mask to df:', endl, df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .isnull and .notnull ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618    False\n",
      "538    False\n",
      "267    False\n",
      "113    False\n",
      "208    False\n",
      "Name: Team, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print emp['Team'].isnull().sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First names of employees without team:\n",
      "781    Lawrence\n",
      "864        Ryan\n",
      "774         NaN\n",
      "479     Richard\n",
      "199    Jonathan\n",
      "Name: First Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print 'First names of employees without team:'\n",
    "print emp['First Name'][emp['Team'].isnull()].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .unique and .nunique #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas' 'Louise' nan 'James' 'Christopher' 'Jonathan' 'Michael' 'Jeremy'\n",
      " 'Bobby' 'Edward' 'Joyce' 'Jason' 'Chris' 'Richard' 'Wanda' 'Jimmy' 'Peter'\n",
      " 'Kimberly' 'Harry' 'Carl' 'Randy' 'Donald' 'Joseph' 'Alice' 'Todd'\n",
      " 'Daniel' 'Antonio' 'Lawrence' 'Nicole' 'Charles' 'Mildred' 'Phillip'\n",
      " 'Ryan' 'Joe']\n"
     ]
    }
   ],
   "source": [
    "print emp['First Name'][emp['Team'].isnull()].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print len(emp['First Name'][emp['Team'].isnull()].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not equal. Why? \n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print 'Not equal. Why?', endl, emp['First Name'][emp['Team'].isnull()].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now they're equal: \n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print \"Now they're equal:\", endl, emp['First Name'][emp['Team'].isnull()].nunique(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sorting and ranking #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Name Gender Start Date     Last Login Time  Salary  Bonus %  Senior Management             Team\n",
      "101      Aaron   Male 2012-02-17 2017-11-27 10:20:00   61602   11.849               True        Marketing\n",
      "327      Aaron   Male 1994-01-29 2017-11-27 18:48:00   58755    5.097               True        Marketing\n",
      "440      Aaron   Male 1990-07-22 2017-11-27 14:53:00   52119   11.343               True  Client Services\n",
      "937      Aaron    NaN 1986-01-22 2017-11-27 19:39:00   63126   18.424              False  Client Services\n",
      "137       Adam   Male 2011-05-21 2017-11-27 01:45:00   95327   15.120              False     Distribution\n"
     ]
    }
   ],
   "source": [
    "# To sort by the values of one or more columns use sort_values method\n",
    "print emp.sort_values(by = 'First Name', na_position = 'last').head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort by \"Start Date\" using index sorting\n",
      "\n",
      "           First Name  Gender     Last Login Time  Salary  Bonus %  Senior Management             Team\n",
      "Start Date                                                                                            \n",
      "2016-07-15      Terry     NaN 2017-11-27 00:29:00  140002   19.490               True        Marketing\n",
      "2016-06-16       Tina  Female 2017-11-27 19:47:00  100705   16.961               True        Marketing\n",
      "2016-06-05    Lillian  Female 2017-11-27 06:09:00   59414    1.256              False          Product\n",
      "2016-05-24        NaN    Male 2017-11-27 21:17:00   76409    7.008               True     Distribution\n",
      "2016-05-12    Lillian     NaN 2017-11-27 15:43:00   64164   17.612              False  Human Resources\n"
     ]
    }
   ],
   "source": [
    "# Create an index by which to sort\n",
    "print 'Sort by \"Start Date\" using index sorting'\n",
    "_0 = emp.set_index(keys = 'Start Date', drop = True)\n",
    "print endl, _0.sort_index(ascending = False, na_position = 'last').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rank` will assign integers to values according to their ordered position.  \n",
    "The ranks can be contiguous or not according to the ranking method. Groups of equal values are always assigned the same rank.  \n",
    "`average` assigns to each equi-valued group the average of their sort-index.  \n",
    "  \n",
    "__NB:__ The ranks of the resulting set are not sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  3  1\n",
      "1  3  1\n",
      "2  0  4\n",
      "3  0  4\n",
      "4  4  0\n"
     ]
    }
   ],
   "source": [
    "# create a dummy DataFrame\n",
    "np.random.seed(101)\n",
    "df = pd.DataFrame(np.random.choice(5, [5, 2]))\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default ranks of first column elements 0    3.5\n",
      "1    3.5\n",
      "2    1.5\n",
      "3    1.5\n",
      "4    5.0\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Default ranking\n",
    "print 'Default ranks of first column elements', df[0].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense ranking \n",
      "   0    0\n",
      "0  3  2.0\n",
      "1  3  2.0\n",
      "2  0  1.0\n",
      "3  0  1.0\n",
      "4  4  3.0\n"
     ]
    }
   ],
   "source": [
    "print 'Dense ranking', endl, pd.concat([df[0], df[0].rank(method = 'dense')], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "# Groupings and transforms #\n",
    "\n",
    "Projections and selections when combined with `.groupby`, `.apply` and `.transform` methods described in the sequel, essentially constitute Panda's powerful framework for multidimensional analysis (MDA).  \n",
    "MDA supported by visualizations (an area we'll explore later) is what has been known as __Exploratory Data Analysis__, a term coined in the 70s by John Tukey, one of the prominent statisticians of our era\n",
    "\n",
    "__Quiz:__ What else is [Tukey known for](https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm)? (it dominated the electronics industry for 3 decades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset ###\n",
    "Create a Dataframe with Sales records of an imaginary retailer.  \n",
    "The retailer sells products identified by their Stock-keeping unit (SKU column) in several stores identified by their ID (STORE column).  \n",
    "Each record contains the number and the price of items (SKUs) sold in a store at a particular day.\n",
    "  \n",
    "For our case assume there're 4 SKUs, 5 stores and we have records from 01May2016 to 31Oct2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SKUs\n",
    "storeSales = pd.DataFrame(np.random.choice(list('ABCD'), 100), columns = ['SKU'])\n",
    "# Stores\n",
    "storeSales['STORE'] = np.random.choice(list('WXYZ'), 100)\n",
    "# Dates\n",
    "storeSales['DAY'] = np.random.choice(pd.date_range(start = dt(2016, 5, 1), end = dt(2017, 10, 31)), 100)\n",
    "#Price: \n",
    "prices = dict(zip(list('ABCD'), np.random.uniform(10, 100, 4)))\n",
    "storeSales['PRICE'] = storeSales['SKU'].map(prices)\n",
    "\n",
    "# Items sold. # Permit 0 sales on item\n",
    "storeSales['SALES'] = np.random.uniform(0, 100, 100).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permit some null prices (e.g. assume some SKUs were sold with coupons of varying markdowns)  \n",
    "__Caveat:__  \n",
    "If you try to use instead\n",
    "``` Python\n",
    "storeSales[np.random.choice([True, False], storeSales.shape[0], p = [.05, .95])]['PRICE'] = np.nan\n",
    "```\n",
    "you get a warning that 'you're trying to a ssign to an implicit copy'.  \n",
    "  \n",
    "We use loc to avoid this. 'loc' returns a __view__ of the underlying data so assignments are safe.\n",
    "  \n",
    "__Quiz:__  \n",
    "Where's the implicit copy in the above statement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SKU STORE        DAY      PRICE  SALES\n",
      "51   A     X 2016-07-15  50.774371     31\n",
      "25   D     Z 2017-08-13  11.601213     62\n",
      "32   D     W 2017-10-01  11.601213     87\n",
      "9    B     X 2016-07-19  28.058070     46\n",
      "19   C     Y 2016-11-07  66.801608      1\n"
     ]
    }
   ],
   "source": [
    "storeSales.loc[np.random.choice([True, False], storeSales.shape[0], p = [.05, .95]), 'PRICE'] = np.nan\n",
    "print storeSales.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sales per STORE per DAY:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STORE  DAY       \n",
       "Y      2017-04-25    59\n",
       "       2016-07-01    62\n",
       "W      2016-07-28    18\n",
       "       2017-09-28    75\n",
       "       2017-09-01    76\n",
       "Name: SALES, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales.groupby(['STORE', 'DAY'])['SALES'].sum().sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Average sales of store X__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SKU\n",
       "A    45.800000\n",
       "B    22.500000\n",
       "C    57.000000\n",
       "D    54.727273\n",
       "Name: SALES, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales[storeSales['STORE'] == 'X'].groupby('SKU')['SALES'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------\n",
    "To answer time queries we use the .dt accessor of Series objects with datetime dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeSales['DAY'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAY\n",
      "0    53.000000\n",
      "1    47.000000\n",
      "2    54.250000\n",
      "3    42.571429\n",
      "4    51.450000\n",
      "5    47.272727\n",
      "6    51.230769\n",
      "Name: SALES, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Monday = 0, Sunday = 6\n",
    "print storeSales.groupby(storeSales['DAY'].dt.dayofweek)['SALES'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "<div style = \"color: darkred; font-size: 200%; font-weight: bold;  text-decoration: underline\"> \n",
    "Exercise \n",
    "</div>  \n",
    "\n",
    "Find the average sales by store on Saturdays"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load -s pandas1 solutions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "We can compute more advanced aggregations using .groupby with function objects:  \n",
    "E.g to compute the sum of sales per week and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAY\n",
      "201651    109\n",
      "201723     90\n",
      "201743    107\n",
      "201638     27\n",
      "201742    157\n",
      "201752     72\n",
      "201707     78\n",
      "201629    126\n",
      "201622     57\n",
      "201635    193\n",
      "Name: SALES, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "yearWeekAsInts = lambda tseries_: tseries_.year * 100 + tseries_.week\n",
    "salesByWeek = storeSales.groupby(yearWeekAsInts(storeSales['DAY'].dt))['SALES'].sum()\n",
    "print salesByWeek.sort_index().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute more complex aggregations you should rather create a column for yearWeeks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR_WEEK  STORE\n",
      "201647     Y         57\n",
      "201626     Y         62\n",
      "201730     Z         59\n",
      "201722     Z         42\n",
      "201733     W         43\n",
      "201717     Z         94\n",
      "201621     Y        105\n",
      "201735     W         76\n",
      "201627     X         75\n",
      "201631     Z        128\n",
      "Name: SALES, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "storeSales['YEAR_WEEK'] = yearWeekAsInts(storeSales['DAY'].dt)\n",
    "print storeSales.groupby(['YEAR_WEEK', 'STORE'])['SALES'].sum().sort_index().sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
